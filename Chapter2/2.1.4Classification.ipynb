{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9773234",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f60c83",
   "metadata": {},
   "source": [
    "In the previous note books we have been looking at the very basics of regression models. Regression models are good for if our data is quantitative. How ever if our data is qualitative we will use classification and classification models to predict outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad8a36c",
   "metadata": {},
   "source": [
    "for classification models we are going to want to build classifiers, which predict an output K based on the proability of that output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290b0258",
   "metadata": {},
   "source": [
    "### Below is Bayes Optimal Classifier:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86474ac",
   "metadata": {},
   "source": [
    "$$\n",
    "C(x) = j \n",
    "\\quad \\text{if} \\quad \n",
    "p_j(x) = \\max \\{\\, p_1(x),\\, p_2(x),\\, \\ldots,\\, p_K(x) \\,\\}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6a49c6",
   "metadata": {},
   "source": [
    "This formula bassically states that given a classifier the output is j if the probability of j at x is the greatest of the probabilities from 1-k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd1e870",
   "metadata": {},
   "source": [
    "for example say we had 4 posible out comes -> left, right, up or down and we are trying to predict which one of these would be the output given some conditions/parameters x. After we have bee given our parameters we find that \n",
    "\n",
    "$ |p_{left}(x) = 0.40, | p_{right}(x) = 0.20  |  p_{up}(x) = 0.30 |   p_{down}(x) = 0.10 |$\n",
    "\n",
    "Using bayes optimal classifier our output should then be  $p_{left}(X)$ because it has the greatest probability at X \n",
    "\n",
    " $\\therefore C(x) = left$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f03c6c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left\n"
     ]
    }
   ],
   "source": [
    "# Simple implimentation of this in python assuming we are given the probabilities\n",
    "# this implimentation is jsut to help see it in code and is not to practical\n",
    "\n",
    "# here we will assume the input comes as an arr of tuples [(left,0.40) (right,0.20)]\n",
    "\n",
    "probs = [(0.40,'left'),(0.20,'right'),(0.30,'up'),(0.10,'down')]\n",
    "\n",
    "def simpleBayesOptimalClassifier(probabilities:list) -> str:\n",
    "\n",
    "    max = probabilities[0]\n",
    "\n",
    "    for x, y in probabilities:\n",
    "        if x > max[0]:\n",
    "            max = (x,y)\n",
    "    \n",
    "    return max[1]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(simpleBayesOptimalClassifier(probs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164e2b22",
   "metadata": {},
   "source": [
    "No Visualizaion here :( but their is one for Classification in KNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
