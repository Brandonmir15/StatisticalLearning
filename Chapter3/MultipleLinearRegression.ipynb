{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05c9e76b",
   "metadata": {},
   "source": [
    "## Multiple Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821bc6e0",
   "metadata": {},
   "source": [
    "When using multiple linear regression our model will look like $$Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... \\beta_nX_n + \\epsilon$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8f1c89",
   "metadata": {},
   "source": [
    "### Understanding the Design matrix:\n",
    " Imagine that we have 2 Features for our them being hight and weight (height, weight) so say that we have values $(66,120)$ $(65, 140)$ and $(70,180)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827f7cfe",
   "metadata": {},
   "source": [
    "Our design matrix would look like this $$\t\\begin{bmatrix}\n",
    "1 & 66 & 120\\\\\n",
    "1 & 65 & 140\\\\\n",
    "1 & 70 & 180\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5243fe87",
   "metadata": {},
   "source": [
    "This is what our values would look like inside of our design matrix. The ones are used for the intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daa1d7d",
   "metadata": {},
   "source": [
    "$$\n",
    "X\\beta =\n",
    "\\begin{bmatrix}\n",
    "1 & x_{11} & x_{12} \\\\\n",
    "1 & x_{21} & x_{22} \\\\\n",
    "1 & x_{31} & x_{32}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\beta_0 \\\\\n",
    "\\beta_1 \\\\\n",
    "\\beta_2\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\beta_0 + \\beta_1 x_{11} + \\beta_2 x_{12} \\\\\n",
    "\\beta_0 + \\beta_1 x_{21} + \\beta_2 x_{22} \\\\\n",
    "\\beta_0 + \\beta_1 x_{31} + \\beta_2 x_{32}\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ef71fa",
   "metadata": {},
   "source": [
    "When using a Desgn Matrix your equation will now take the form $$\\hat{y} = X\\beta$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a83e76",
   "metadata": {},
   "source": [
    "For multiple linear regression we still want to do the same thing as we did in simple linear regression and minimize the sum of squared errors. The only problem is there is no closed solution for this, so the way that we do it is via gradient decent. Gradient decent is basically an itterative process that will get us closer to the minimum value of the sum of squared errors "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6c35bf",
   "metadata": {},
   "source": [
    "## We will find the weights of these coeeficients by using gradient decent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4d8dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def gradientDescent(x, y, step=0.01, itterations=1000):\n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "\n",
    "    \n",
    "   \n",
    "    weights = np.zeros(p) # start off with a guess of the coeffients and work from there\n",
    "    \n",
    "    for i in range(itterations):\n",
    "        prediction = x @ weights              #we are going to get our predicito\n",
    "        error = prediction - y      \n",
    "               \n",
    "        gradient = (2/n) * (x.T @ error)  # gradient exuation will provied derivation in future\n",
    "        weights = weights - step * gradient       # update each step\n",
    "        \n",
    "\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee24030",
   "metadata": {},
   "source": [
    "Once The weights are found using Gradient Decent. If you perform matrix multiple on the inputs and the weights you will get your predicted value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13a1b5a",
   "metadata": {},
   "source": [
    "$$\\hat{y} = X\\beta$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59823757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(weights, newInputs:list[float]):\n",
    "    x = np.array(newInputs) # here we change our array to an np array\n",
    "    if X.ndim == 1:\n",
    "        X = X.reshape(1, -1)\n",
    "\n",
    "    ones = np.ones((X.shape[0], 1)) # Here we need to add our 1's to the first column to get our intercept values\n",
    "    X = np.hstack((ones, X)) \n",
    "\n",
    "    return x @ weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
